@echo off
chcp 65001 > nul
cls

echo.
echo â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
echo â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
echo â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
echo â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘
echo â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
echo  â•šâ•â•â•â•â•â• â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•  â•šâ•â•    â•šâ•â•â•šâ•â•  â•šâ•â•
echo.
echo ðŸ§  INSTALADOR AUTOMÃTICO DE SOFIA INTELIGENTE
echo ================================================
echo.

REM Verificar directorio
if not exist "python_embeded" (
    echo âŒ ERROR: Ejecuta desde la carpeta Sofia_Novia_Virtual
    echo ðŸ’¡ Debe existir la carpeta python_embeded
    pause
    exit /b 1
)

echo ðŸ” Verificando sistema...
echo.

REM Verificar Python
python_embeded\python.exe --version > nul 2>&1
if errorlevel 1 (
    echo âŒ Python no funciona
    pause
    exit /b 1
) else (
    echo âœ… Python OK
)

REM Verificar Ollama
echo ðŸ¦™ Verificando Ollama...
ollama --version > nul 2>&1
if errorlevel 1 (
    echo âŒ OLLAMA NO INSTALADO
    echo.
    echo ðŸ“¥ INSTALAR OLLAMA:
    echo 1. Ve a: https://ollama.ai
    echo 2. Descarga Ollama para Windows
    echo 3. Instala y reinicia
    echo 4. Ejecuta este script de nuevo
    pause
    exit /b 1
) else (
    echo âœ… Ollama instalado
)

REM Verificar si Ollama estÃ¡ corriendo
echo ðŸ”„ Verificando servicio Ollama...
curl -s http://localhost:11434/api/tags > nul 2>&1
if errorlevel 1 (
    echo âš ï¸  Ollama no estÃ¡ corriendo
    echo ðŸš€ Iniciando Ollama...
    start /b ollama serve
    timeout /t 5 > nul
    
    REM Verificar de nuevo
    curl -s http://localhost:11434/api/tags > nul 2>&1
    if errorlevel 1 (
        echo âŒ No se pudo iniciar Ollama automÃ¡ticamente
        echo ðŸ’¡ Inicia manualmente: ollama serve
        pause
        exit /b 1
    ) else (
        echo âœ… Ollama iniciado
    )
) else (
    echo âœ… Ollama funcionando
)

REM Instalar dependencias Python
echo ðŸ“¦ Instalando dependencias Python...
python_embeded\python.exe -m pip install --quiet --upgrade pip
python_embeded\python.exe -m pip install --quiet flask requests

echo.
echo ðŸ¦™ Verificando modelos de IA...

REM Listar modelos
for /f "tokens=*" %%i in ('curl -s http://localhost:11434/api/tags ^| python_embeded\python.exe -c "import sys, json; data=json.load(sys.stdin); print(len(data.get('models', [])))"') do set NUM_MODELS=%%i

if "%NUM_MODELS%"=="0" (
    echo âŒ No hay modelos de IA instalados
    echo.
    echo ðŸŽ¯ INSTALANDO LLAMA 3.2...
    echo â³ Esto puede tardar varios minutos dependiendo de tu conexiÃ³n
    echo ðŸ“Š Llama 3.2 pesa aproximadamente 4.7GB
    echo.
    
    ollama pull llama3.2
    
    if errorlevel 1 (
        echo âŒ Error descargando Llama 3.2
        echo ðŸ’¡ Intenta manualmente: ollama pull llama3.2
        pause
        exit /b 1
    ) else (
        echo âœ… Llama 3.2 instalado correctamente
    )
) else (
    echo âœ… Modelos encontrados: %NUM_MODELS%
)

echo.
echo ðŸ§ª Probando sistema completo...
echo.

REM Crear script de prueba
echo import requests, json > test_sofia.py
echo try: >> test_sofia.py
echo     response = requests.get("http://localhost:11434/api/tags", timeout=5) >> test_sofia.py
echo     if response.status_code == 200: >> test_sofia.py
echo         models = response.json().get('models', []) >> test_sofia.py
echo         if models: >> test_sofia.py
echo             print("âœ… Sistema IA listo") >> test_sofia.py
echo             print(f"ðŸ“¦ Modelos: {len(models)}") >> test_sofia.py
echo             for model in models[:3]: >> test_sofia.py
echo                 print(f"   ðŸ§  {model['name']}") >> test_sofia.py
echo         else: >> test_sofia.py
echo             print("âŒ No hay modelos") >> test_sofia.py
echo     else: >> test_sofia.py
echo         print("âŒ Ollama error") >> test_sofia.py
echo except Exception as e: >> test_sofia.py
echo     print(f"âŒ Error: {e}") >> test_sofia.py

python_embeded\python.exe test_sofia.py
del test_sofia.py

echo.
echo ðŸŽ‰ INSTALACIÃ“N COMPLETADA
echo ========================
echo.
echo âœ… Python funcionando
echo âœ… Ollama funcionando  
echo âœ… Llama 3 instalado
echo âœ… Dependencias instaladas
echo.
echo ðŸš€ PRÃ“XIMOS PASOS:
echo 1. Ejecuta: python_embeded\python.exe sofia_inteligente.py
echo 2. Abre: http://localhost:7860
echo 3. Â¡Conversa con Sofia IA!
echo.
echo ðŸ’¡ COMANDOS ÃšTILES:
echo - Verificar: python_embeded\python.exe verificar_ollama.py
echo - Sofia bÃ¡sica: python_embeded\python.exe sofia.py
echo - Sofia IA: python_embeded\python.exe sofia_inteligente.py
echo.

pause